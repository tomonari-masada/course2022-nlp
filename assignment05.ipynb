{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_hxmw_rJXVQRznUkirSLaRrV7YkAihto",
      "authorship_tag": "ABX9TyPMrCig89ctWTgcay1lRo8y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2022-nlp/blob/main/assignment05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx2zN0IvyqF"
      },
      "source": [
        "# 課題5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (A) fasttextの単語埋め込みを使ったモデル"
      ],
      "metadata": {
        "id": "KO5kH-ZrAxXS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-jw4S8rhTB"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjF1vzSosL5l"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/2022Courses/nlp/imdb/'\n",
        "\n",
        "texts = {}\n",
        "labels = {}\n",
        "for tag in ['train', 'test']:\n",
        "  with open(f'{PATH}{tag}.npy', 'rb') as f:\n",
        "    texts[tag] = np.load(f)\n",
        "  with open(f'{PATH}{tag}_labels.npy', 'rb') as f:\n",
        "    labels[tag] = np.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuEe746MtFtr"
      },
      "source": [
        "for tag in ['train', 'test']:\n",
        "  texts[tag] = torch.tensor(texts[tag])\n",
        "  labels[tag] = torch.tensor(labels[tag])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]"
      ],
      "metadata": {
        "id": "xPkyiWjkppeu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1osG09aHppg1"
      },
      "source": [
        "train_dataset = MyDataset(texts['train'], labels['train'])\n",
        "test_dataset = MyDataset(texts['test'], labels['test'])\n",
        "\n",
        "valid_size = len(train_dataset) // 5\n",
        "train_size = len(train_dataset) - valid_size\n",
        "split_train_, split_valid_ = random_split(train_dataset, [train_size, valid_size])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfloEv0Osj2n"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(split_valid_, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YDOQzmVr0N6"
      },
      "source": [
        "### モデルを変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkRnetIrs9DX"
      },
      "source": [
        "class TextSentiment(nn.Module):\n",
        "  def __init__(self, emsize, num_class, hdim=1024):\n",
        "    super(TextSentiment, self).__init__()\n",
        "    self.fc_in = nn.Linear(emsize, hdim)\n",
        "    self.fc1 = nn.Linear(hdim, hdim)\n",
        "    self.fc2 = nn.Linear(hdim, hdim)\n",
        "    self.fc_out = nn.Linear(hdim, num_class)\n",
        "    self.ln_in = nn.LayerNorm(emsize)\n",
        "    self.ln1 = nn.LayerNorm(hdim)\n",
        "    self.ln2 = nn.LayerNorm(hdim)\n",
        "    self.ln_out = nn.LayerNorm(hdim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.ln_in(x)\n",
        "    x = self.fc_in(x)\n",
        "    x = self.ln1(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.ln2(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.ln_out(x)\n",
        "    x = self.fc_out(x)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkGnlqfvQpp"
      },
      "source": [
        "EMSIZE = texts['train'].size(1) # 埋め込みベクトルの次元\n",
        "NUM_CLASS = len(np.unique(labels['train'])) # クラスの個数\n",
        "\n",
        "model = TextSentiment(EMSIZE, NUM_CLASS, hdim=2048).to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0NIxhlxka5"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 50])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0ko1VZz_Kng"
      },
      "source": [
        "### 訓練を行なう関数\n",
        "* lossの監視も追加。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHvS00cVvaVU"
      },
      "source": [
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  total_count = 0\n",
        "  for input, target in dataloader:\n",
        "    input, target = input.to(device), target.to(device)\n",
        "    output = model(input)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss.item() * len(target)\n",
        "    total_acc += (output.argmax(1) == target).sum().item()\n",
        "    total_count += len(target) # 表示用の集計\n",
        "  return total_acc / total_count, total_loss / total_count"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0ARJYib_M84"
      },
      "source": [
        "### 評価を行なう関数\n",
        "* lossの監視も追加。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDFVMgRqyl4Q"
      },
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  total_count = 0\n",
        "  for input, target in dataloader:\n",
        "    with torch.no_grad():\n",
        "      input, target = input.to(device), target.to(device)\n",
        "      output = model(input)\n",
        "      loss = criterion(output, target)\n",
        "      total_loss += loss.item() * len(target)\n",
        "      total_acc += (output.argmax(1) == target).sum().item()\n",
        "      total_count += len(target)\n",
        "  return total_acc / total_count, total_loss / total_count"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEAiT90S4qae"
      },
      "source": [
        "### 訓練と評価の実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAXpaWNwxqWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5667044b-c672-4786-c4f7-9b1a0f398390"
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  epoch_start_time = time.time()\n",
        "  train_acc, train_loss = train(train_loader)\n",
        "  val_acc, val_loss = evaluate(valid_loader)\n",
        "  if val_loss < best_val_loss:\n",
        "    best_val_loss = val_loss\n",
        "    torch.save(model.state_dict(), f\"model.pt\")\n",
        "  scheduler.step()\n",
        "  print(f'epoch {epoch:3d} || '\n",
        "        f'lr={scheduler.get_last_lr()[0]:.3e} | '\n",
        "        f'time: {time.time() - epoch_start_time:5.2f}s || '\n",
        "        f'train loss {train_loss:.4f} | '\n",
        "        f'train accuracy {train_acc:8.3f} || '\n",
        "        f'val loss {val_loss:.4f} | '\n",
        "        f'val accuracy {val_acc:8.3f}'\n",
        "        )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch   1 || lr=1.000e-05 | time:  3.68s || train loss 0.5011 | train accuracy    0.756 || val loss 0.3902 | val accuracy    0.826\n",
            "epoch   2 || lr=1.000e-05 | time:  1.17s || train loss 0.3826 | train accuracy    0.832 || val loss 0.3533 | val accuracy    0.846\n",
            "epoch   3 || lr=1.000e-05 | time:  1.16s || train loss 0.3598 | train accuracy    0.844 || val loss 0.3485 | val accuracy    0.852\n",
            "epoch   4 || lr=1.000e-05 | time:  1.17s || train loss 0.3565 | train accuracy    0.847 || val loss 0.3447 | val accuracy    0.851\n",
            "epoch   5 || lr=1.000e-05 | time:  1.10s || train loss 0.3561 | train accuracy    0.846 || val loss 0.3499 | val accuracy    0.848\n",
            "epoch   6 || lr=1.000e-05 | time:  1.09s || train loss 0.3458 | train accuracy    0.851 || val loss 0.3728 | val accuracy    0.838\n",
            "epoch   7 || lr=1.000e-05 | time:  1.10s || train loss 0.3433 | train accuracy    0.853 || val loss 0.3560 | val accuracy    0.844\n",
            "epoch   8 || lr=1.000e-05 | time:  1.08s || train loss 0.3422 | train accuracy    0.852 || val loss 0.3454 | val accuracy    0.849\n",
            "epoch   9 || lr=1.000e-05 | time:  1.09s || train loss 0.3475 | train accuracy    0.849 || val loss 0.3543 | val accuracy    0.845\n",
            "epoch  10 || lr=1.000e-06 | time:  1.09s || train loss 0.3383 | train accuracy    0.854 || val loss 0.3484 | val accuracy    0.853\n",
            "epoch  11 || lr=1.000e-06 | time:  1.17s || train loss 0.3287 | train accuracy    0.859 || val loss 0.3355 | val accuracy    0.856\n",
            "epoch  12 || lr=1.000e-06 | time:  1.08s || train loss 0.3261 | train accuracy    0.861 || val loss 0.3362 | val accuracy    0.857\n",
            "epoch  13 || lr=1.000e-06 | time:  1.09s || train loss 0.3259 | train accuracy    0.861 || val loss 0.3360 | val accuracy    0.859\n",
            "epoch  14 || lr=1.000e-06 | time:  1.17s || train loss 0.3264 | train accuracy    0.860 || val loss 0.3355 | val accuracy    0.856\n",
            "epoch  15 || lr=1.000e-06 | time:  1.09s || train loss 0.3257 | train accuracy    0.861 || val loss 0.3386 | val accuracy    0.854\n",
            "epoch  16 || lr=1.000e-06 | time:  1.18s || train loss 0.3263 | train accuracy    0.861 || val loss 0.3348 | val accuracy    0.856\n",
            "epoch  17 || lr=1.000e-06 | time:  1.10s || train loss 0.3255 | train accuracy    0.861 || val loss 0.3353 | val accuracy    0.857\n",
            "epoch  18 || lr=1.000e-06 | time:  1.19s || train loss 0.3254 | train accuracy    0.862 || val loss 0.3348 | val accuracy    0.857\n",
            "epoch  19 || lr=1.000e-06 | time:  1.09s || train loss 0.3257 | train accuracy    0.860 || val loss 0.3367 | val accuracy    0.856\n",
            "epoch  20 || lr=1.000e-06 | time:  1.10s || train loss 0.3250 | train accuracy    0.861 || val loss 0.3391 | val accuracy    0.852\n",
            "epoch  21 || lr=1.000e-06 | time:  1.19s || train loss 0.3251 | train accuracy    0.861 || val loss 0.3345 | val accuracy    0.856\n",
            "epoch  22 || lr=1.000e-06 | time:  1.10s || train loss 0.3252 | train accuracy    0.861 || val loss 0.3357 | val accuracy    0.858\n",
            "epoch  23 || lr=1.000e-06 | time:  1.10s || train loss 0.3253 | train accuracy    0.861 || val loss 0.3355 | val accuracy    0.858\n",
            "epoch  24 || lr=1.000e-06 | time:  1.18s || train loss 0.3238 | train accuracy    0.862 || val loss 0.3344 | val accuracy    0.858\n",
            "epoch  25 || lr=1.000e-06 | time:  1.09s || train loss 0.3245 | train accuracy    0.861 || val loss 0.3381 | val accuracy    0.854\n",
            "epoch  26 || lr=1.000e-06 | time:  1.09s || train loss 0.3243 | train accuracy    0.861 || val loss 0.3351 | val accuracy    0.857\n",
            "epoch  27 || lr=1.000e-06 | time:  1.10s || train loss 0.3242 | train accuracy    0.862 || val loss 0.3350 | val accuracy    0.857\n",
            "epoch  28 || lr=1.000e-06 | time:  1.18s || train loss 0.3259 | train accuracy    0.862 || val loss 0.3342 | val accuracy    0.857\n",
            "epoch  29 || lr=1.000e-06 | time:  1.09s || train loss 0.3238 | train accuracy    0.862 || val loss 0.3371 | val accuracy    0.855\n",
            "epoch  30 || lr=1.000e-06 | time:  1.10s || train loss 0.3241 | train accuracy    0.861 || val loss 0.3344 | val accuracy    0.858\n",
            "epoch  31 || lr=1.000e-06 | time:  1.18s || train loss 0.3234 | train accuracy    0.862 || val loss 0.3341 | val accuracy    0.858\n",
            "epoch  32 || lr=1.000e-06 | time:  1.11s || train loss 0.3236 | train accuracy    0.862 || val loss 0.3342 | val accuracy    0.858\n",
            "epoch  33 || lr=1.000e-06 | time:  1.10s || train loss 0.3243 | train accuracy    0.862 || val loss 0.3389 | val accuracy    0.854\n",
            "epoch  34 || lr=1.000e-06 | time:  1.20s || train loss 0.3227 | train accuracy    0.862 || val loss 0.3341 | val accuracy    0.859\n",
            "epoch  35 || lr=1.000e-06 | time:  1.11s || train loss 0.3245 | train accuracy    0.861 || val loss 0.3341 | val accuracy    0.858\n",
            "epoch  36 || lr=1.000e-06 | time:  1.10s || train loss 0.3233 | train accuracy    0.862 || val loss 0.3350 | val accuracy    0.858\n",
            "epoch  37 || lr=1.000e-06 | time:  1.22s || train loss 0.3235 | train accuracy    0.861 || val loss 0.3342 | val accuracy    0.858\n",
            "epoch  38 || lr=1.000e-06 | time:  1.30s || train loss 0.3242 | train accuracy    0.861 || val loss 0.3340 | val accuracy    0.859\n",
            "epoch  39 || lr=1.000e-06 | time:  1.17s || train loss 0.3230 | train accuracy    0.863 || val loss 0.3394 | val accuracy    0.853\n",
            "epoch  40 || lr=1.000e-06 | time:  1.18s || train loss 0.3225 | train accuracy    0.863 || val loss 0.3338 | val accuracy    0.859\n",
            "epoch  41 || lr=1.000e-06 | time:  1.11s || train loss 0.3230 | train accuracy    0.861 || val loss 0.3464 | val accuracy    0.848\n",
            "epoch  42 || lr=1.000e-06 | time:  1.19s || train loss 0.3226 | train accuracy    0.863 || val loss 0.3337 | val accuracy    0.859\n",
            "epoch  43 || lr=1.000e-06 | time:  1.10s || train loss 0.3242 | train accuracy    0.861 || val loss 0.3388 | val accuracy    0.853\n",
            "epoch  44 || lr=1.000e-06 | time:  1.11s || train loss 0.3227 | train accuracy    0.863 || val loss 0.3348 | val accuracy    0.857\n",
            "epoch  45 || lr=1.000e-06 | time:  1.21s || train loss 0.3225 | train accuracy    0.861 || val loss 0.3368 | val accuracy    0.857\n",
            "epoch  46 || lr=1.000e-06 | time:  1.23s || train loss 0.3228 | train accuracy    0.862 || val loss 0.3384 | val accuracy    0.855\n",
            "epoch  47 || lr=1.000e-06 | time:  1.21s || train loss 0.3238 | train accuracy    0.861 || val loss 0.3349 | val accuracy    0.857\n",
            "epoch  48 || lr=1.000e-06 | time:  1.10s || train loss 0.3233 | train accuracy    0.861 || val loss 0.3352 | val accuracy    0.859\n",
            "epoch  49 || lr=1.000e-06 | time:  1.10s || train loss 0.3229 | train accuracy    0.861 || val loss 0.3349 | val accuracy    0.857\n",
            "epoch  50 || lr=1.000e-07 | time:  1.10s || train loss 0.3221 | train accuracy    0.863 || val loss 0.3391 | val accuracy    0.855\n",
            "epoch  51 || lr=1.000e-07 | time:  1.10s || train loss 0.3200 | train accuracy    0.862 || val loss 0.3341 | val accuracy    0.857\n",
            "epoch  52 || lr=1.000e-07 | time:  1.10s || train loss 0.3198 | train accuracy    0.863 || val loss 0.3340 | val accuracy    0.857\n",
            "epoch  53 || lr=1.000e-07 | time:  1.09s || train loss 0.3199 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  54 || lr=1.000e-07 | time:  1.09s || train loss 0.3199 | train accuracy    0.863 || val loss 0.3344 | val accuracy    0.857\n",
            "epoch  55 || lr=1.000e-07 | time:  1.09s || train loss 0.3198 | train accuracy    0.862 || val loss 0.3339 | val accuracy    0.857\n",
            "epoch  56 || lr=1.000e-07 | time:  1.09s || train loss 0.3199 | train accuracy    0.862 || val loss 0.3351 | val accuracy    0.858\n",
            "epoch  57 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  58 || lr=1.000e-07 | time:  1.09s || train loss 0.3198 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  59 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.863 || val loss 0.3339 | val accuracy    0.858\n",
            "epoch  60 || lr=1.000e-07 | time:  1.10s || train loss 0.3200 | train accuracy    0.863 || val loss 0.3356 | val accuracy    0.859\n",
            "epoch  61 || lr=1.000e-07 | time:  1.09s || train loss 0.3198 | train accuracy    0.862 || val loss 0.3342 | val accuracy    0.855\n",
            "epoch  62 || lr=1.000e-07 | time:  1.10s || train loss 0.3198 | train accuracy    0.862 || val loss 0.3358 | val accuracy    0.858\n",
            "epoch  63 || lr=1.000e-07 | time:  1.09s || train loss 0.3198 | train accuracy    0.862 || val loss 0.3355 | val accuracy    0.859\n",
            "epoch  64 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  65 || lr=1.000e-07 | time:  1.08s || train loss 0.3199 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.859\n",
            "epoch  66 || lr=1.000e-07 | time:  1.09s || train loss 0.3198 | train accuracy    0.863 || val loss 0.3342 | val accuracy    0.855\n",
            "epoch  67 || lr=1.000e-07 | time:  1.08s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3339 | val accuracy    0.857\n",
            "epoch  68 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.862 || val loss 0.3339 | val accuracy    0.857\n",
            "epoch  69 || lr=1.000e-07 | time:  1.08s || train loss 0.3196 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.857\n",
            "epoch  70 || lr=1.000e-07 | time:  1.12s || train loss 0.3199 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.859\n",
            "epoch  71 || lr=1.000e-07 | time:  1.11s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3353 | val accuracy    0.858\n",
            "epoch  72 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3343 | val accuracy    0.857\n",
            "epoch  73 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.863 || val loss 0.3338 | val accuracy    0.859\n",
            "epoch  74 || lr=1.000e-07 | time:  1.09s || train loss 0.3199 | train accuracy    0.862 || val loss 0.3340 | val accuracy    0.856\n",
            "epoch  75 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  76 || lr=1.000e-07 | time:  1.10s || train loss 0.3196 | train accuracy    0.862 || val loss 0.3340 | val accuracy    0.856\n",
            "epoch  77 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.863 || val loss 0.3342 | val accuracy    0.855\n",
            "epoch  78 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.863 || val loss 0.3360 | val accuracy    0.857\n",
            "epoch  79 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.863 || val loss 0.3350 | val accuracy    0.858\n",
            "epoch  80 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.862 || val loss 0.3342 | val accuracy    0.855\n",
            "epoch  81 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.863 || val loss 0.3342 | val accuracy    0.855\n",
            "epoch  82 || lr=1.000e-07 | time:  1.10s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3343 | val accuracy    0.857\n",
            "epoch  83 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.862 || val loss 0.3348 | val accuracy    0.857\n",
            "epoch  84 || lr=1.000e-07 | time:  1.10s || train loss 0.3195 | train accuracy    0.862 || val loss 0.3351 | val accuracy    0.858\n",
            "epoch  85 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.863 || val loss 0.3352 | val accuracy    0.858\n",
            "epoch  86 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.863 || val loss 0.3367 | val accuracy    0.857\n",
            "epoch  87 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  88 || lr=1.000e-07 | time:  1.10s || train loss 0.3193 | train accuracy    0.863 || val loss 0.3352 | val accuracy    0.858\n",
            "epoch  89 || lr=1.000e-07 | time:  1.10s || train loss 0.3195 | train accuracy    0.863 || val loss 0.3342 | val accuracy    0.856\n",
            "epoch  90 || lr=1.000e-07 | time:  1.09s || train loss 0.3194 | train accuracy    0.863 || val loss 0.3338 | val accuracy    0.859\n",
            "epoch  91 || lr=1.000e-07 | time:  1.09s || train loss 0.3197 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  92 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.862 || val loss 0.3338 | val accuracy    0.858\n",
            "epoch  93 || lr=1.000e-07 | time:  1.09s || train loss 0.3196 | train accuracy    0.863 || val loss 0.3349 | val accuracy    0.858\n",
            "epoch  94 || lr=1.000e-07 | time:  1.09s || train loss 0.3193 | train accuracy    0.863 || val loss 0.3355 | val accuracy    0.858\n",
            "epoch  95 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.862 || val loss 0.3344 | val accuracy    0.857\n",
            "epoch  96 || lr=1.000e-07 | time:  1.09s || train loss 0.3191 | train accuracy    0.862 || val loss 0.3364 | val accuracy    0.857\n",
            "epoch  97 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.863 || val loss 0.3340 | val accuracy    0.856\n",
            "epoch  98 || lr=1.000e-07 | time:  1.10s || train loss 0.3195 | train accuracy    0.862 || val loss 0.3347 | val accuracy    0.858\n",
            "epoch  99 || lr=1.000e-07 | time:  1.09s || train loss 0.3195 | train accuracy    0.863 || val loss 0.3339 | val accuracy    0.856\n",
            "epoch 100 || lr=1.000e-07 | time:  1.09s || train loss 0.3193 | train accuracy    0.863 || val loss 0.3338 | val accuracy    0.858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ハイパーパラメータのチューニングが済んだら、テストセットで評価する。"
      ],
      "metadata": {
        "id": "Mi5MZ1-GGcUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "test_acc, _ = evaluate(test_loader)\n",
        "print(f'test accuracy {test_acc:8.3f}')"
      ],
      "metadata": {
        "id": "4trquZpJGgop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3abc52b3-812b-4fed-ebaa-c4a7ad1c43a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy    0.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlumE8Khl7tN"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}