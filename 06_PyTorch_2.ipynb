{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlJ2Zr/Ho0IUTeJixFmpHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2022-nlp/blob/main/06_PyTorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HumXxZix0r0F"
      },
      "source": [
        "# PyTorch入門（2）\n",
        "参考資料: \n",
        "* PyTorch公式のチュートリアル \n",
        " * https://pytorch.org/tutorials/index.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX7vFs7IJh5K"
      },
      "source": [
        "* reproducibilityについては下記リンク先を参照\n",
        " * https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki1IHrFY1B0J"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt6hJJOC00hz"
      },
      "source": [
        "## 線形回帰\n",
        "* 線形回帰モデルのミニバッチ学習をPyTorchで書いてみる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkVV10QS04Z6"
      },
      "source": [
        "### 人工的にデータを作る\n",
        " * $y = w_1 x_1 + w_2 x_2 + b + \\epsilon$という式にしたがってデータを生成する。\n",
        "  * $\\epsilon$は正規分布に従うとする。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9CNqcC50zUu"
      },
      "source": [
        "# データ数\n",
        "DATA_SIZE = 1000\n",
        "\n",
        "# ランダムな二次元ベクトルの集合を訓練データとして設定\n",
        "X = 10 * torch.rand(DATA_SIZE, 2) - 5.0\n",
        "\n",
        "# 係数と切片（これに近い値が求まればよい）\n",
        "w_true = torch.tensor([[2.0], [-3.0]])\n",
        "b_true = torch.tensor([10.0])\n",
        "\n",
        "# 正規乱数を加えた値がターゲット\n",
        "y = X @ w_true + b_true + torch.normal(0.0, 2.0, size=[DATA_SIZE, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqCxr9NHO8yN"
      },
      "source": [
        "### torch.utils.data.Datasetの利用\n",
        "* `torch.utils.data.Dataset`を継承して自分用のデータセットのクラスを定義する。\n",
        "* 以下の２つの関数を必ず書く。\n",
        " * データセットの長さを返す関数\n",
        " * 与えられたインデックスに対応するアイテムを返す関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_tNcrjsIS4y"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEklKEEfVGIi"
      },
      "source": [
        "* train : valid : test = 8 : 1 : 1 に分割する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW_iAHjHVCW8"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "dataset = MyDataset(X, y)\n",
        "\n",
        "test_size = len(dataset) // 10\n",
        "valid_size = test_size\n",
        "train_size = len(dataset) - valid_size - test_size\n",
        "train, valid, test = random_split(dataset, [train_size, valid_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqEMzr7cKoc6"
      },
      "source": [
        "print(len(train), len(valid), len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 分割した後は、`torch.utils.data.Dataset`ではなく、`torch.utils.data.dataset.Subset`になる。"
      ],
      "metadata": {
        "id": "bPv-KYazlNFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(train)"
      ],
      "metadata": {
        "id": "zyyGnb2LlTsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `torch.utils.data.dataset.Subset`については、`.dataset`とすれば、データの内容にアクセスできる。"
      ],
      "metadata": {
        "id": "TNSzUziklzwh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAIqOz1wqnd2"
      },
      "source": [
        "train.dataset.X[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dataset.y[:5]"
      ],
      "metadata": {
        "id": "grVMT1VFl7P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I7YBl2DPDD_"
      },
      "source": [
        "### 訓練データを可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trYloF231kRn"
      },
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "ax1 = plt.subplot(121)\n",
        "ax1.scatter(train.dataset.X[:, 0].numpy(), train.dataset.y.numpy(), c=\"b\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"y\", rotation=0)\n",
        "\n",
        "ax2 = plt.subplot(122)\n",
        "ax2.scatter(train.dataset.X[:, 1].numpy(), train.dataset.y.numpy(), c=\"g\")\n",
        "plt.xlabel(\"x2\")\n",
        "plt.ylabel(\"y\", rotation=0)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm7eB5jCPLk3"
      },
      "source": [
        "### torch.utils.data.DataLoaderの利用\n",
        "* 訓練データをシャッフルしてミニバッチをひとつずつ取り出す処理を、PyTorchのDataLoaderを使って実装する。\n",
        " * https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "* 評価に使うデータセットはシャッフルしなくてよい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq12Qs8KMXqQ"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ミニバッチのサイズ\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# 訓練データだけシャッフル\n",
        "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* データローダの長さは、ミニバッチの個数。インスタンスの個数ではない。"
      ],
      "metadata": {
        "id": "6BYdmNKQnFmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "id": "d1B3omXHnBcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練データの最初のミニバッチだけ見てみる。"
      ],
      "metadata": {
        "id": "V4ZIJID4nM5B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svJOzzlmlNkS"
      },
      "source": [
        "print(next(iter(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QObgXLk26yQx"
      },
      "source": [
        "### モデルの定義\n",
        "* 値を推定したいのは、線形モデル$y = w_1 x_1 + w_2 x_2 + b$の係数$w_1,w_2$と切片$b$。\n",
        "* そこで、係数と切片を微分可能なテンソルとして用意する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEwTHRWz6Lym"
      },
      "source": [
        "w = torch.randn((2, 1), requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erBDyaw_KsBi"
      },
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2mw1jJF6aEF"
      },
      "source": [
        "### 損失関数\n",
        "* 平均二乗誤差を使う。\n",
        "* PyTorchで用意されている損失関数については、下のリンク先を参照。\n",
        " * https://pytorch.org/docs/stable/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azz3iDWU6X9P"
      },
      "source": [
        "criterion = torch.nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEgaQkHQ6e8B"
      },
      "source": [
        "### 最適化アルゴリズム\n",
        "* SGDを使う。\n",
        "* PyTorchで用意されているoptimizerについては、下のリンク先を参照。\n",
        " * https://pytorch.org/docs/stable/optim.html#algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULsUK_jV6dGS"
      },
      "source": [
        "optimizer = torch.optim.SGD([w, b], lr=0.0001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxtW5Hu-bPPV"
      },
      "source": [
        "### 学習のループ\n",
        "* ループのなかには、最低限、以下の４つを書く\n",
        " * PyTorchの最近のチュートリアルではパラメータの更新直後にgradientをゼロにしている。\n",
        "1. 損失関数の値を計算することによって、計算グラフを作る\n",
        "2. backpropagationの実行\n",
        "3. パラメータの更新\n",
        "4. gradientをゼロにする\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm6sreTk3zZt"
      },
      "source": [
        "for epoch in range(30):\n",
        "\n",
        "  train_loss = 0.0\n",
        "  for input, target in train_loader:\n",
        "    output = input @ w + b\n",
        "    loss = criterion(output, target)\n",
        "    train_loss += loss.item() * len(target) # 表示用の集計\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  # valid lossの計算\n",
        "  valid_loss = 0\n",
        "  for input, target in valid_loader:\n",
        "    with torch.no_grad():\n",
        "      output = input @ w + b\n",
        "      loss = criterion(output, target)\n",
        "      valid_loss += loss.item() * len(target)\n",
        "\n",
        "  # ログをとる\n",
        "  print(f'epoch {epoch+1:4d} ;',\n",
        "        f'train loss {train_loss/train_size:8.4f} ;',\n",
        "        f'valid loss {valid_loss/valid_size:8.4f} ;',\n",
        "        f'[{\" \".join([\"{:8.4f}\".format(e.item()) for e in w])}]',\n",
        "        f'{b.item():8.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhp2A3pkWaFn"
      },
      "source": [
        "* 評価用のヘルパ関数を定義しておく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq0pGq3ftPQo"
      },
      "source": [
        "def eval(loader):\n",
        "  total_loss = 0.0\n",
        "  total_size = 0\n",
        "  for input, target in loader:\n",
        "    with torch.no_grad():\n",
        "      output = input @ w + b\n",
        "      loss = criterion(output, target)\n",
        "      total_loss += loss.item() * len(target)\n",
        "      total_size += len(target)\n",
        "\n",
        "  return total_loss / total_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gps-Bc9wPDA"
      },
      "source": [
        "print(f'test loss : {eval(test_loader):8.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNwAN3SVM_W9"
      },
      "source": [
        "## TensorBoardによる可視化\n",
        "* TensorBoardを使ってみる。\n",
        " * https://pytorch.org/docs/stable/tensorboard.html\n",
        "* 上の線形回帰モデルの学習をもう一度そのままおこない、結果を可視化する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmXF9KKPMgD"
      },
      "source": [
        "### TensorBoardのnotebook extensionをロードしておく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu-s78eUYimE"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJaW01i1NYe3"
      },
      "source": [
        "### TensorBoardを使う準備\n",
        "* PyTorchのSummaryWriterを使う。\n",
        "* デフォルトの設定では、「runs」というディレクトリの下にイベント・ファイルが保存される。\n",
        "* SummaryWriterのlog_dirというパラメータで、イベント・ファイルを保存するディレクトリを指定することもできる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hnP787wPyAs"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJvP5ZWoNhlf"
      },
      "source": [
        "### モデルと損失関数と最適化アルゴリズムの準備\n",
        "* （上ですでにおこなったことを、改めてもう一度書いているだけです。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFvf0dEPQz-7"
      },
      "source": [
        "w = torch.randn((2, 1), requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w, b], lr=0.0001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IebJO8dUMGaH"
      },
      "source": [
        "### SummaryWriterを使って損失関数の値を記録する\n",
        "* add_scalarメソッドを使っている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_1mkEnLWk7x"
      },
      "source": [
        "for epoch in range(30):\n",
        "\n",
        "  train_loss = 0.0\n",
        "  for input, target in train_loader:\n",
        "    output = input @ w + b\n",
        "    loss = criterion(output, target)\n",
        "    train_loss += loss.item() * len(target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  writer.add_scalar('loss/training', train_loss / train_size, epoch)\n",
        "\n",
        "  valid_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for input, target in valid_loader:\n",
        "      output = input @ w + b\n",
        "      loss = criterion(output, target)\n",
        "      valid_loss += loss.item() * len(target)\n",
        "\n",
        "  writer.add_scalar('loss/valid', valid_loss / valid_size, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6576NL0MaCt"
      },
      "source": [
        "### SummaryWriterを閉じる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q1QCSRqf9fI"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjJaOsBOMgjM"
      },
      "source": [
        "### 記録した損失関数の値をプロットする"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 絵が出てくるまで、少し時間がかかるかもしれません・・・。"
      ],
      "metadata": {
        "id": "IIJf2SwUmQ5-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "striB6BwXePM"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngJV09JR8dF"
      },
      "source": [
        "## nn.Sequentialのインスタンスとしてモデルを作る\n",
        "* requires_grad=Trueでテンソルを作ればモデルを用意することはできる。\n",
        "* しかし、同じことは、torch.nnを使えばもっとすっきり実現できる。\n",
        "* まず、nn.Sequentialを使う方法を示す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufK1j4NUQuzg"
      },
      "source": [
        "### nn.Sequentialのインスタンスとしてモデルを作る\n",
        "* 下記のようにモデルを作った時点でレイヤのパラメータは初期化されている。\n",
        "* この初期化には上でセットした乱数のシードが使われている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMrXPs8j7AvJ"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upR9Es1yNFNZ"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiNUUuRpak-C"
      },
      "source": [
        "type(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_7hvKfH7PO2"
      },
      "source": [
        "# パラメータがどのように初期化されているかを確認してみる\n",
        "for p in model.parameters():\n",
        "  print(p.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjKTOSb-QbFw"
      },
      "source": [
        "### 損失関数とoptimizer\n",
        "* optimizerにはモデルのパラメータを渡す。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A0f6tkbX11b"
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak-6vuxtNPGr"
      },
      "source": [
        "### 学習のループ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3qhwI60gENN"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HCE8FD07o_w"
      },
      "source": [
        "for epoch in range(30):\n",
        "\n",
        "  train_loss = 0.0\n",
        "  for input, target in train_loader:\n",
        "    output = model(input)\n",
        "    loss = criterion(output, target)\n",
        "    train_loss += loss.item() * len(target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  writer.add_scalar('loss/training', train_loss / train_size, epoch)\n",
        "\n",
        "  # valid loss\n",
        "  valid_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for input, target in valid_loader:\n",
        "      output = model(input)\n",
        "      loss = criterion(output, target)\n",
        "      valid_loss += loss.item() * len(target)\n",
        "\n",
        "  writer.add_scalar('loss/valid', valid_loss / valid_size, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rge3-23BO2-u"
      },
      "source": [
        "### モデルのグラフを表示させる\n",
        "* SummaryWriterのadd_graphメソッドを使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHbdCLF976b3"
      },
      "source": [
        "# 訓練データの最初のインスタンス（どのインスタンスでもよい）でグラフを作る\n",
        "writer.add_graph(model, next(iter(train_loader))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6vRbhKfgF7P"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* GRAPHSというタブで計算グラフを見ることができる。\n",
        " * 計算グラフのノードをダブルクリックしてみよう。"
      ],
      "metadata": {
        "id": "0Uh6tpdGnr1f"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYo-F8EKY1zs"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO43yHMyapoA"
      },
      "source": [
        "## nn.Moduleを継承してモデルを作る\n",
        "* nn.Moduleを継承するクラスを定義する。\n",
        "* そしてそのクラスのインスタンスとしてモデルを作る。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinearModel(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.fc(input)"
      ],
      "metadata": {
        "id": "TyD69Xs9m6K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 自分で初期化する場合"
      ],
      "metadata": {
        "id": "kHffigkBm6-p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8hNpEznZZFj"
      },
      "source": [
        "class MyLinearModel(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(input_size, output_size)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    self.fc.weight.data.normal_()\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.fc(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYYTbktFb9zV"
      },
      "source": [
        "model = MyLinearModel(2, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI3UMZc7d7NS"
      },
      "source": [
        "# パラメータがどのように初期化されているかを確認してみる\n",
        "for p in model.parameters():\n",
        "  print(p.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "303BtfTqd8aC"
      },
      "source": [
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s71a9ARngVCf"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTdfKC0BdtmC"
      },
      "source": [
        "for epoch in range(30):\n",
        "\n",
        "  train_loss = 0\n",
        "  for input, target in train_loader:\n",
        "    output = model(input)\n",
        "    loss = criterion(output, target)\n",
        "    train_loss += loss.item() * len(target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  writer.add_scalar('loss/training', train_loss / train_size, epoch)\n",
        "\n",
        "  # valid loss\n",
        "  valid_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for input, target in valid_loader:\n",
        "      output = model(input)\n",
        "      loss = criterion(output, target)\n",
        "      valid_loss += loss.item() * len(target)\n",
        "\n",
        "  writer.add_scalar('loss/valid', valid_loss / valid_size, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Hvd6GsgZXa"
      },
      "source": [
        "writer.add_graph(model, next(iter(train_loader))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nywRcHNZgTdV"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8zaEduEefFR"
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueuLb_SM0AtG"
      },
      "source": [
        "* これは課題ではないが、GPUを使うように書き直してみよう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6ysayiRhEcw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}